# -*- coding: utf-8 -*-
"""Day-4 DS Practicals.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JhQyamj5zTAD4cjpFUfWSKkY1I4ziM_i

#1.Introduction to data wrangling and preprocessing

Data Wrangling: Data wrangling is the process of cleaning, structuring, and enriching raw data to make it more usable for analysis or machine learning models.

Data Preprocessing: Data preprocessing is a subset of data wrangling that focuses on preparing the dataset for machine learning by ensuring quality and consistency.

#2.Handling missing values and duplicates

Identify missing values
"""

from google.colab import files
import pandas as pd
import io

uploaded = files.upload() # Upload your CSV file

# Get the filename from the uploaded dictionary
filename = list(uploaded.keys())[0]

# Read the file using io.BytesIO to handle the uploaded content
df = pd.read_csv(io.BytesIO(uploaded[filename]))

df.head()

"""Techniques to handle missing data

A. Remove missing values
"""

df_cleaned = df.dropna()  # Removes rows with missing values
print(df_cleaned)

"""B. Fill missing values(imputation)

• Fill with mean/median(for numerical data)
"""

df["Age"].fillna(df["Age"].mean(), inplace=True)
df["Marks"].fillna(df["Marks"].median(), inplace=True)
df["Attendance"].fillna(df["Attendance"].mean(), inplace=True)

"""• Fill with mode(for categorical data)"""

df["Passed"].fillna(df["Passed"].mode()[0], inplace=True)

"""• Forward fill and backward fill"""

df.ffill(inplace=True) # Forward fill
df.bfill(inplace=True) # Backward fill

"""Remove duplicates"""

df.drop_duplicates(inplace=True)

"""#3.Data transformation:scaling and encoding

Standardization(Z-Score normalization)
"""

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df_scaled = df.copy()
df_scaled[["Marks", "Attendance"]] = scaler.fit_transform(df[["Marks", "Attendance"]])
print(df_scaled)

"""Min-Max scaling"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df_scaled[["Marks", "Attendance"]] = scaler.fit_transform(df[["Marks", "Attendance"]])
print(df_scaled)

"""One-Hot encoding"""

df_encoded = pd.get_dummies(df, columns=["Passed"],
drop_first=True)
print(df_encoded)

"""Lable encoding"""

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
df["Passed"] = encoder.fit_transform(df["Passed"])
print(df)

"""#4.Feature engineering

Creating new features

Deriving a new feature:performance category
"""

def performance_category(marks):
    if marks >= 85:
        return "High"
    elif marks >= 60:
        return "Medium"
    else:
        return "Low"

"""Binning(converting continuous to categorical data)"""

df["Age_Group"] = pd.cut(df["Age"], bins=[18, 21, 24],
labels=["Young", "Adult"])
print(df)