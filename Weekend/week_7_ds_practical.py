# -*- coding: utf-8 -*-
"""Week-7 DS Practical.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aUyfum-UgOhK6rUGj1cgEPHv4dcV52ko

#Implementing Linear Regression
Implementation Steps:

● Load the dataset (California housing data).
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
# Load dataset (e.g., Boston Housing Prices)
from sklearn.datasets import fetch_california_housing
data = fetch_california_housing()
df = pd.DataFrame(data.data, columns=data.feature_names)
df['Price'] = data.target
df.head()

"""● Preprocess the data (select features and target variable)."""

# Select Features and Target
X = df[['MedInc', 'HouseAge', 'AveRooms']] # Selecting some features
y = df['Price']
# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,
random_state=42)

"""● Train a Linear Regression model using Scikit-learn."""

model = LinearRegression()
model.fit(X_train, y_train)

"""● Evaluate model performance using RMSE and R² score."""

y_pred = model.predict(X_test)
# Performance Metrics
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)
print(f'RMSE: {rmse:.2f}')
print(f'R-squared: {r2:.2f}')

"""● Visualize predictions using a scatter plot."""

plt.scatter(y_test, y_pred)
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual vs Predicted Prices")
plt.show()

"""#Implementing Logistic Regression
Implementation Steps:

● Load the dataset ( Cancer dataset from sklearn).
"""

from sklearn.datasets import load_breast_cancer
data = load_breast_cancer()
df = pd.DataFrame(data.data, columns=data.feature_names)
df['Target'] = data.target
df.head()

"""● Split the dataset into training and testing sets."""

# Features and Target
X = df.iloc[:, :-1] # All features except target
y = df['Target']
# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,
random_state=42)

"""● Train a Logistic Regression model using Scikit-learn."""

from sklearn.linear_model import LogisticRegression
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

"""● Use classification metrics such as accuracy, confusion matrix, and
classification report.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Load dataset (e.g., California Housing Prices)
from sklearn.datasets import fetch_california_housing
data = fetch_california_housing()
df = pd.DataFrame(data.data, columns=data.feature_names)
df['Price'] = data.target

# Select Features and Target
X = df[['MedInc', 'HouseAge', 'AveRooms']]
y = df['Price']

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and Train the Linear Regression Model
model = LinearRegression()  # Defining the model
model.fit(X_train, y_train)  # Training the model

# Prediction and Evaluation for Linear Regression
y_pred = model.predict(X_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)
print(f'RMSE: {rmse:.2f}')
print(f'R-squared: {r2:.2f}')

plt.scatter(y_test, y_pred)
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual vs Predicted Prices")
plt.show()

# Load the Breast Cancer Dataset
from sklearn.datasets import load_breast_cancer
data = load_breast_cancer()
df = pd.DataFrame(data.data, columns=data.feature_names)
df['Target'] = data.target

# Features and Target
X = df.iloc[:, :-1]
y = df['Target']

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and Train the Logistic Regression Model
from sklearn.linear_model import LogisticRegression
model = LogisticRegression(max_iter=1000)  # Defining the model
model.fit(X_train, y_train)  # Training the model

# Prediction and Evaluation for Logistic Regression
y_pred = model.predict(X_test)
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("Classification Report:")
print(classification_report(y_test, y_pred))

"""● Visualize the confusion matrix using a heatmap."""

import seaborn as sns
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

"""#Hyperparameter Tuning

Optimizing Logistic Regression using GridSearchCV:
"""

from sklearn.model_selection import GridSearchCV
param_grid = {'C': [0.1, 1, 10, 100]}
grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)
grid.fit(X_train, y_train)
print(f"Best Parameters: {grid.best_params_}")
print(f"Best Accuracy: {grid.best_score_:.2f}")